{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc13f538-1d87-4f73-8568-cd9f467aabf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import statements and setup matplotlib for jupyter\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Import statements and setup matplotlib for jupyter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285680a3-44d7-4f8f-9fa4-7b94f692a2d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load data into a dataframe\u001b[39;00m\n\u001b[0;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/PacktPublishing/Machine-Learning-with-R-Third-Edition/master/Chapter07/letterdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load data into a dataframe\n",
    "url = 'https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-with-R-Third-Edition/master/Chapter07/letterdata.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529dfb7f-dad3-4fd0-9528-076f4335767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     # Create ANN architecture. 16 input nodes, 3 hidden layers of 50 nodes, output player of 26 nodes\n",
    "#     def __init__(self, input_features=16, h1=50, h2=50, h3=50, h4=50, output_features=26):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(input_features, h1)\n",
    "#         self.fc2 = nn.Linear(h1, h2)\n",
    "#         self.fc3 = nn.Linear(h2, h3)\n",
    "#         self.fc4 = nn.Linear(h3, h4)\n",
    "#         self.out = nn.Linear(h4, output_features)\n",
    "\n",
    "#     #Feed forward function\n",
    "#     def forward(self, x):\n",
    "#         # Using the exponential linear unit activation function\n",
    "#         x = F.elu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = F.elu(self.fc3(x))\n",
    "#         x = F.relu(self.fc4(x))\n",
    "#         x = self.out(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91431c54-a5e0-4282-91a1-b9b7d9839611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    # Create ANN architecture. 16 input nodes, 3 hidden layers of 50 nodes, output player of 26 nodes\n",
    "    def __init__(self, input_features=16, h1=60, h2=60, output_features=26):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, output_features)\n",
    "\n",
    "    #Feed forward function\n",
    "    def forward(self, x):\n",
    "        # Using the exponential linear unit activation function\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22103b80-ec54-4e2d-a493-1aad28a2f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducible results\n",
    "torch.manual_seed(100)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35868cd1-6020-436f-b57f-47e0fbc8c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data format\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd521810-62d9-45de-bf78-b9e0bb0c882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale all numeric values into a small range. We will use min-max scaling.\n",
    "# df_numeric = df.drop(columns=[\"letter\"])\n",
    "# min_max_scalar = preprocessing.MinMaxScaler()\n",
    "# df_numeric_minmax = min_max_scalar.fit_transform(df_numeric)\n",
    "# df_numeric_minmax = pd.DataFrame(df_numeric_minmax)\n",
    "# df_numeric_minmax.insert(0, \"letter\", df[\"letter\"])\n",
    "# df = df_numeric_minmax\n",
    "\n",
    "# df_normalized = df.drop(columns=['letter'])\n",
    "# df_normalized = preprocessing.normalize(df_normalized, norm='l2')\n",
    "# df_normalized = pd.DataFrame(df_normalized)\n",
    "# df_normalized.insert(0, \"letter\", df[\"letter\"])\n",
    "# df = df_normalized\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65b3d4-1c40-42cc-80aa-7a743dab41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# df_dropped = df.drop(columns=['letter'])\n",
    "# print(scaler.fit(df_dropped))\n",
    "# print(scaler.mean_)\n",
    "# print(scaler.transform(df_dropped))\n",
    "# df_dropped = pd.DataFrame(scaler.transform(df_dropped))\n",
    "# df_dropped.insert(0, \"letter\", df[\"letter\"])\n",
    "# df = df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e00cba-c189-4233-9313-5e70108b40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace each character in the letter column with a numeric value for compatability\n",
    "chars=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "i = 0.0\n",
    "for j in chars:\n",
    "    df['letter'] = df['letter'].replace(j, i)\n",
    "    i +=1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d613cd-74f7-4242-a8b8-742c7006cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate predictors (X) and labels (y) \n",
    "X = df.drop('letter', axis=1)\n",
    "y = df['letter']\n",
    "\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b463f9-ef93-4b34-829b-25448db0c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into an 80% training set and 20% testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=800)\n",
    "\n",
    "# Set tensor accuracy\n",
    "# In the future set up for GPU processing using cuda\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea170e-16fb-4475-9438-6f3ed439d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the error and select optimization method with a learning rate of 0.001\n",
    "# Higher lr of 0.05 was resulting in overfitting at high epochs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791fac5-8dee-4fd8-b5a1-ed3b40134d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "epochs = 3000\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    y_pred = model.forward(X_train) \n",
    "    #Measure error\n",
    "    loss = criterion(y_pred, y_train) \n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    # Setup back propagation for tuning weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Graph the rate of error at each epoch\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e91eae-3b54-4dce-b839-d811aca7b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        # Make predictions using test data\n",
    "        y_val = model.forward(data)\n",
    "\n",
    "        # Check how many are correct\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "percent = correct/y_test.shape[0] * 100\n",
    "print(f'{correct} / {y_test.shape[0]} = {percent}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb38528-4235-4cb2-8139-898851863204",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "\n",
    "        #Letter classifier prediction\n",
    "        print(f'{i+1}.) {str(y_val)} \\t {y_test[i]} \\t {y_val.argmax().item()}')\n",
    "\n",
    "        #Correct or not\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "print(f'We got {correct} correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4335e-0a2a-41b0-8958-69cce7d5811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chars[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91d3af-4e3b-4961-a4b6-3663b16720a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chars[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f2bf74-2fb1-40a2-891e-a7feaa1ae60b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
